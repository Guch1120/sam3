{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae39ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SAM 3 を使用したインタラクティブなインスタンスセグメンテーション (Interactive Instance Segmentation using SAM 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-setup-md",
   "metadata": {},
   "source": [
    "## Google Colab セットアップ\n",
    "\n",
    "Google Colabで実行する場合は、以下のセルを実行してください。\n",
    "これにより、必要なライブラリのインストールと、データの読み込み準備が行われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab環境のセットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Colab環境で実行中\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ローカル環境で実行中\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Google Driveをマウント (推奨)\n",
    "    # 自分のデータやコードを使用する場合は、Google Driveにアップロードしてマウントします\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # 2. SAM3のインストールとパス設定\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    # Google Drive内のSAM3ディレクトリのパス\n",
    "    # ※ご自身の環境に合わせてパスを変更してください\n",
    "    DRIVE_SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "    \n",
    "    if os.path.exists(DRIVE_SAM3_PATH):\n",
    "        print(f\"Google Drive内のSAM3が見つかりました: {DRIVE_SAM3_PATH}\")\n",
    "        os.chdir(DRIVE_SAM3_PATH)\n",
    "        print(\"カレントディレクトリを変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        print(\"依存関係をインストールしています...\")\n",
    "        # Numpy 2.0との互換性問題を回避するためにバージョンを固定\n",
    "        !pip install -q \"numpy<2.0\"\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "        \n",
    "    else:\n",
    "        print(f\"Google Drive内に {DRIVE_SAM3_PATH} が見つかりませんでした。\")\n",
    "        print(\"GitHubからSAM3をクローンしてインストールします...\")\n",
    "        \n",
    "        # GitHubからクローン\n",
    "        if not os.path.exists(\"/content/sam3\"):\n",
    "            !git clone https://github.com/facebookresearch/sam3.git /content/sam3\n",
    "            \n",
    "        os.chdir(\"/content/sam3\")\n",
    "        print(\"カレントディレクトリを /content/sam3 に変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        # Numpy 2.0との互換性問題を回避するためにバージョンを固定\n",
    "        !pip install -q \"numpy<2.0\"\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "    \n",
    "    print(\"セットアップが完了しました。\")\n",
    "    print(f\"現在の作業ディレクトリ: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-data-usage",
   "metadata": {},
   "source": [
    "### データの使用について\n",
    "\n",
    "- **Google Driveを使用する場合**: `GT_DIR` や `PRED_DIR` には `/content/drive/MyDrive/...` から始まるパスを指定してください。\n",
    "- **GitHubからクローンした場合**: 左側のファイルブラウザから `/content/sam3` 内を確認できます。データは別途アップロードが必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab環境のセットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Colab環境で実行中\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ローカル環境で実行中\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Google Driveをマウント (推奨)\n",
    "    # 自分のデータやコードを使用する場合は、Google Driveにアップロードしてマウントします\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # 2. SAM3のインストールとパス設定\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    # Google Drive内のSAM3ディレクトリのパス\n",
    "    # ※ご自身の環境に合わせてパスを変更してください\n",
    "    DRIVE_SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "    \n",
    "    if os.path.exists(DRIVE_SAM3_PATH):\n",
    "        print(f\"Google Drive内のSAM3が見つかりました: {DRIVE_SAM3_PATH}\")\n",
    "        os.chdir(DRIVE_SAM3_PATH)\n",
    "        print(\"カレントディレクトリを変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        print(\"依存関係をインストールしています...\")\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "        \n",
    "    else:\n",
    "        print(f\"Google Drive内に {DRIVE_SAM3_PATH} が見つかりませんでした。\")\n",
    "        print(\"GitHubからSAM3をクローンしてインストールします...\")\n",
    "        \n",
    "        # GitHubからクローン\n",
    "        if not os.path.exists(\"/content/sam3\"):\n",
    "            !git clone https://github.com/facebookresearch/sam3.git /content/sam3\n",
    "            \n",
    "        os.chdir(\"/content/sam3\")\n",
    "        print(\"カレントディレクトリを /content/sam3 に変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "    \n",
    "    print(\"セットアップが完了しました。\")\n",
    "    print(f\"現在の作業ディレクトリ: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-data-usage",
   "metadata": {},
   "source": [
    "### データの使用について\n",
    "\n",
    "- **Google Driveを使用する場合**: `GT_DIR` や `PRED_DIR` には `/content/drive/MyDrive/...` から始まるパスを指定してください。\n",
    "- **GitHubからクローンした場合**: 左側のファイルブラウザから `/content/sam3` 内を確認できます。データは別途アップロードが必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4b25c",
   "metadata": {},
   "source": [
    "Segment Anything Model 3 (SAM 3) は、幾何学的なプロンプト (SAM 1 タスク) を与えられると、目的のオブジェクトを示すインスタンスマスクを予測します。\n",
    "`SAM3Image` クラスと `Sam3Processor` クラスは、モデルにプロンプトを与えるための簡単なインターフェースを提供します。\n",
    "ユーザーはまず `Sam3Processor.set_image` メソッドを使用して画像を設定し、必要な画像埋め込み (embeddings) を計算します。\n",
    "その後、`predict` メソッドを介してプロンプトを提供することで、それらのプロンプトからマスクを効率的に予測できます。\n",
    "モデルは入力として、ポイントプロンプトとボックスプロンプトの両方、および前の予測イテレーションからのマスクを受け取ることができます。\n",
    "\n",
    "このノートブックは、インタラクティブな画像セグメンテーションのための SAM 2 API に従っています。\n",
    "\n",
    "# <a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/sam3/blob/main/notebooks/sam3_for_sam1_task_example.ipynb\">\n",
    "#   <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "# </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644532a8",
   "metadata": {},
   "source": [
    "## 環境設定 (Environment Set-up)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fabfee",
   "metadata": {},
   "source": [
    "まず、リポジトリの [インストール手順](https://github.com/facebookresearch/sam3?tab=readme-ov-file#installation) に従って、環境に `sam3` をインストールしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be845da",
   "metadata": {},
   "source": [
    "## セットアップ (Set-up)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33681dd1",
   "metadata": {},
   "source": [
    "必要なインポートと、ポイント、ボックス、マスクを表示するためのヘルパー関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe773ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79250a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib scikit-learn\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam3.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b28288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Apple MPSを使用している場合、サポートされていない操作についてはCPUにフォールバックします\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sam3\n",
    "sam3_root = os.path.join(os.path.dirname(sam3.__file__), \"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a15e2f-c7e1-4e5d-862f-fcb751a60b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算に使用するデバイスを選択\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # ノートブック全体でbfloat16を使用\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    # Ampere GPU向けにtfloat32を有効化 (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "elif device.type == \"mps\":\n",
    "    print(\n",
    "        \"\\nSupport for MPS devices is preliminary. SAM 3 is trained with CUDA and might \"\n",
    "        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n",
    "        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders = True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "        # 輪郭を滑らかにする\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))    \n",
    "\n",
    "def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # ボックス\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23842fb2",
   "metadata": {},
   "source": [
    "## 画像の例 (Example image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(f\"{sam3_root}/assets/images/truck.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30125fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b228b8",
   "metadata": {},
   "source": [
    "## SAM 3 でオブジェクトを選択する (Selecting objects with SAM 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1927b",
   "metadata": {},
   "source": [
    "まず、SAM 3 モデルを読み込みます。最良の結果を得るには、CUDA上で実行し、デフォルトのモデルを使用することをお勧めします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam3 import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "bpe_path = f\"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "model = build_sam3_image_model(bpe_path=bpe_path, enable_inst_interactivity=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925e829",
   "metadata": {},
   "source": [
    "`Sam3Processor.set_image` を呼び出して画像を処理し、画像埋め込み (image embedding) を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Sam3Processor(model)\n",
    "inference_state = processor.set_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fc7a46",
   "metadata": {},
   "source": [
    "トラックを選択するには、トラック上の点を選択します。点は (x,y) 形式でモデルに入力され、ラベル 1 (前景点) または 0 (背景点) が付与されます。\n",
    "複数の点を入力できますが、ここでは1つだけ使用します。選択された点は画像上に星印で表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[520, 375]])\n",
    "input_label = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ba973",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765e952",
   "metadata": {},
   "source": [
    "`SAM3Image.predict_inst` で予測を行います。モデルはマスク、それらのマスクの品質予測 (scores)、および次の予測イテレーションに渡すことができる低解像度のマスクロジット (logits) を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, scores, logits = model.predict_inst(\n",
    "    inference_state,\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=True,\n",
    ")\n",
    "sorted_ind = np.argsort(scores)[::-1]\n",
    "masks = masks[sorted_ind]\n",
    "scores = scores[sorted_ind]\n",
    "logits = logits[sorted_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0e938",
   "metadata": {},
   "source": [
    "`multimask_output=True` (デフォルト設定) の場合、SAM 3 は3つのマスクを出力します。ここで `scores` は、これらのマスクの品質に対するモデル自身の推定値を与えます。\n",
    "この設定は曖昧な入力プロンプトを対象としており、モデルがプロンプトと一致する異なるオブジェクトを区別するのに役立ちます。\n",
    "`False` の場合、単一のマスクを返します。\n",
    "単一の点のような曖昧なプロンプトの場合、単一のマスクのみが必要な場合でも `multimask_output=True` を使用することをお勧めします。\n",
    "`scores` で返された最高スコアのマスクを選択することで、最適な単一マスクを選択できます。これにより、多くの場合、より良いマスクが得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47821187",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape  # (マスクの数) x H x W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c227a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(image, masks, scores, point_coords=input_point, input_labels=input_label, borders=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa31f7c",
   "metadata": {},
   "source": [
    "## 追加のポイントで特定のオブジェクトを指定する (Specifying a specific object with additional points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6d29a",
   "metadata": {},
   "source": [
    "単一の入力点は曖昧であり、モデルはそれと一致する複数のオブジェクトを返しました。単一のオブジェクトを取得するには、複数の点を提供できます。\n",
    "利用可能な場合、前のイテレーションからのマスクをモデルに提供して、予測を支援することもできます。\n",
    "複数のプロンプトで単一のオブジェクトを指定する場合、`multimask_output=False` を設定することで単一のマスクを要求できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6923b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[500, 375], [1125, 625]])\n",
    "input_label = np.array([1, 1])\n",
    "\n",
    "mask_input = logits[np.argmax(scores), :, :]  # モデルの最良のマスクを選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, scores, _ = model.predict_inst(\n",
    "    inference_state,\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    mask_input=mask_input[None, :, :],\n",
    "    multimask_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(image, masks, scores, point_coords=input_point, input_labels=input_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e2087",
   "metadata": {},
   "source": [
    "車を除外して窓だけを指定するには、背景点 (ラベル 0、ここでは赤で表示) を指定できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a196f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[500, 375], [1125, 625]])\n",
    "input_label = np.array([1, 0])\n",
    "\n",
    "mask_input = logits[np.argmax(scores), :, :]  # モデルの最良のマスクを選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a52282",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, scores, _ = model.predict_inst(\n",
    "    inference_state,\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    mask_input=mask_input[None, :, :],\n",
    "    multimask_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(image, masks, scores, point_coords=input_point, input_labels=input_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2d5a9",
   "metadata": {},
   "source": [
    "## ボックスで特定のオブジェクトを指定する (Specifying a specific object with a box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ca7ac",
   "metadata": {},
   "source": [
    "モデルは、xyxy形式で提供されるボックスを入力として受け取ることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea92a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_box = np.array([425, 600, 700, 875])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, scores, _ = model.predict_inst(\n",
    "    inference_state,\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_box[None, :],\n",
    "    multimask_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(image, masks, scores, box_coords=input_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed9f0a",
   "metadata": {},
   "source": [
    "## ポイントとボックスの組み合わせ (Combining points and boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455d1c5",
   "metadata": {},
   "source": [
    "ポイントとボックスは、予測器に両方のタイプのプロンプトを含めるだけで組み合わせることができます。\n",
    "ここでは、ホイール全体ではなく、トラックのタイヤだけを選択するために使用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_box = np.array([425, 600, 700, 875])\n",
    "input_point = np.array([[575, 750]])\n",
    "input_label = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, scores, logits = model.predict_inst(\n",
    "    inference_state,\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    box=input_box,\n",
    "    multimask_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb519a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(image, masks, scores, box_coords=input_box, point_coords=input_point, input_labels=input_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ddbca3",
   "metadata": {},
   "source": [
    "## バッチプロンプト入力 (Batched prompt inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f18a0",
   "metadata": {},
   "source": [
    "`SAM3Image` は、`predict_inst` メソッドを使用して、同じ画像に対して複数の入力プロンプトを受け取ることができます。\n",
    "たとえば、物体検出器からの複数のボックス出力がある場合を想像してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_boxes = np.array([\n",
    "    [75, 275, 1725, 850],\n",
    "    [425, 600, 700, 875],\n",
    "    [1375, 550, 1650, 800],\n",
    "    [1240, 675, 1400, 750],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117521a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, scores, _ = model.predict_inst(\n",
    "    inference_state,\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_boxes,\n",
    "    multimask_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape  # (バッチサイズ) x (入力ごとの予測マスク数) x H x W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "for mask in masks:\n",
    "    show_mask(mask.squeeze(0), plt.gca(), random_color=True)\n",
    "for box in input_boxes:\n",
    "    show_box(box, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a27b5d",
   "metadata": {},
   "source": [
    "## エンドツーエンドのバッチ推論 (End-to-end batched inference)\n",
    "\n",
    "すべてのプロンプトが事前に利用可能な場合は、SAM 3 をエンドツーエンドで直接実行することが可能です。これにより、画像に対するバッチ処理も可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image  # 上記の truck.jpg\n",
    "image1_boxes = np.array([\n",
    "    [75, 275, 1725, 850],\n",
    "    [425, 600, 700, 875],\n",
    "    [1375, 550, 1650, 800],\n",
    "    [1240, 675, 1400, 750],\n",
    "])\n",
    "\n",
    "image2 = Image.open(f\"{sam3_root}/assets/images/groceries.jpg\")\n",
    "image2_boxes = np.array([\n",
    "    [450, 170, 520, 350],\n",
    "    [350, 190, 450, 350],\n",
    "    [500, 170, 580, 350],\n",
    "    [580, 170, 640, 350],\n",
    "])\n",
    "\n",
    "img_batch = [image1, image2]\n",
    "boxes_batch = [image1_boxes, image2_boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47932c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_state = processor.set_image_batch(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_batch, scores_batch, _ = model.predict_inst_batch(\n",
    "    inference_state,\n",
    "    None,\n",
    "    None, \n",
    "    box_batch=boxes_batch, \n",
    "    multimask_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226df881",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, boxes, masks in zip(img_batch, boxes_batch, masks_batch):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)   \n",
    "    for mask in masks:\n",
    "        show_mask(mask.squeeze(0), plt.gca(), random_color=True)\n",
    "    for box in boxes:\n",
    "        show_box(box, plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f30085",
   "metadata": {},
   "source": [
    "同様に、画像のバッチに対して定義されたポイントプロンプトのバッチを持つこともできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab929fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image  # 上記の truck.jpg\n",
    "image1_pts = np.array([\n",
    "    [[500, 375]],\n",
    "    [[650, 750]]\n",
    "    ]) # Bx1x2 ここでBはオブジェクトの数に対応します\n",
    "image1_labels = np.array([[1], [1]])\n",
    "\n",
    "image2_pts = np.array([\n",
    "    [[400, 300]],\n",
    "    [[630, 300]],\n",
    "])\n",
    "image2_labels = np.array([[1], [1]])\n",
    "\n",
    "pts_batch = [image1_pts, image2_pts]\n",
    "labels_batch = [image1_labels, image2_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_batch, scores_batch, _ = model.predict_inst_batch(inference_state, pts_batch, labels_batch, box_batch=None, multimask_output=True)\n",
    "\n",
    "# オブジェクトごとに最適な単一マスクを選択\n",
    "best_masks = []\n",
    "for masks, scores in zip(masks_batch,scores_batch):\n",
    "    best_masks.append(masks[range(len(masks)), np.argmax(scores, axis=-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b15c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, points, labels, masks in zip(img_batch, pts_batch, labels_batch, best_masks):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)   \n",
    "    for mask in masks:\n",
    "        show_mask(mask, plt.gca(), random_color=True)\n",
    "    show_points(points, labels, plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1594a5-a0de-4477-91d4-db4504a78a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3d07e-b0de-48a5-9d29-d639a0dbcdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1de3a-a253-48ff-8a1c-d80742acbe86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}