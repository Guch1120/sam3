{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0e0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11912666",
   "metadata": {},
   "source": [
    "# SAM 3 画像バッチ推論 (SAM 3 Image Batched Inference)\n",
    "\n",
    "このノートブックでは、SAM 3 モデルを使用して、複数の画像に対する推論をバッチ処理（まとめて処理）する方法を解説します。\n",
    "データポイントの作成、前処理、バッチ化、モデルによる推論、そして結果の視覚化までの流れをステップバイステップで学びます。\n",
    "\n",
    "# <a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/sam3/blob/main/notebooks/sam3_image_batched_inference.ipynb\">\n",
    "#   <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "# </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-setup-md",
   "metadata": {},
   "source": [
    "## Google Colab セットアップ\n",
    "\n",
    "Google Colabで実行する場合は、以下のセルを実行してください。\n",
    "これにより、必要なライブラリのインストールと、データの読み込み準備が行われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab環境のセットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Colab環境で実行中\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ローカル環境で実行中\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Google Driveをマウント (推奨)\n",
    "    # 自分のデータやコードを使用する場合は、Google Driveにアップロードしてマウントします\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # 2. SAM3のインストールとパス設定\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    # Google Drive内のSAM3ディレクトリのパス\n",
    "    # ※ご自身の環境に合わせてパスを変更してください\n",
    "    DRIVE_SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "    \n",
    "    if os.path.exists(DRIVE_SAM3_PATH):\n",
    "        print(f\"Google Drive内のSAM3が見つかりました: {DRIVE_SAM3_PATH}\")\n",
    "        os.chdir(DRIVE_SAM3_PATH)\n",
    "        print(\"カレントディレクトリを変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        print(\"依存関係をインストールしています...\")\n",
    "        # Numpy 2.0との互換性問題を回避するためにバージョンを固定\n",
    "        !pip install -q \"numpy<2.0\"\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "        \n",
    "    else:\n",
    "        print(f\"Google Drive内に {DRIVE_SAM3_PATH} が見つかりませんでした。\")\n",
    "        print(\"GitHubからSAM3をクローンしてインストールします...\")\n",
    "        \n",
    "        # GitHubからクローン\n",
    "        if not os.path.exists(\"/content/sam3\"):\n",
    "            !git clone https://github.com/facebookresearch/sam3.git /content/sam3\n",
    "            \n",
    "        os.chdir(\"/content/sam3\")\n",
    "        print(\"カレントディレクトリを /content/sam3 に変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        # Numpy 2.0との互換性問題を回避するためにバージョンを固定\n",
    "        !pip install -q \"numpy<2.0\"\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "    \n",
    "    print(\"セットアップが完了しました。\")\n",
    "    print(f\"現在の作業ディレクトリ: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-data-usage",
   "metadata": {},
   "source": [
    "### データの使用について\n",
    "\n",
    "- **Google Driveを使用する場合**: `GT_DIR` や `PRED_DIR` には `/content/drive/MyDrive/...` から始まるパスを指定してください。\n",
    "- **GitHubからクローンした場合**: 左側のファイルブラウザから `/content/sam3` 内を確認できます。データは別途アップロードが必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab環境のセットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Colab環境で実行中\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ローカル環境で実行中\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Google Driveをマウント (推奨)\n",
    "    # 自分のデータやコードを使用する場合は、Google Driveにアップロードしてマウントします\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # 2. SAM3のインストールとパス設定\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    # Google Drive内のSAM3ディレクトリのパス\n",
    "    # ※ご自身の環境に合わせてパスを変更してください\n",
    "    DRIVE_SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "    \n",
    "    if os.path.exists(DRIVE_SAM3_PATH):\n",
    "        print(f\"Google Drive内のSAM3が見つかりました: {DRIVE_SAM3_PATH}\")\n",
    "        os.chdir(DRIVE_SAM3_PATH)\n",
    "        print(\"カレントディレクトリを変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        print(\"依存関係をインストールしています...\")\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "        \n",
    "    else:\n",
    "        print(f\"Google Drive内に {DRIVE_SAM3_PATH} が見つかりませんでした。\")\n",
    "        print(\"GitHubからSAM3をクローンしてインストールします...\")\n",
    "        \n",
    "        # GitHubからクローン\n",
    "        if not os.path.exists(\"/content/sam3\"):\n",
    "            !git clone https://github.com/facebookresearch/sam3.git /content/sam3\n",
    "            \n",
    "        os.chdir(\"/content/sam3\")\n",
    "        print(\"カレントディレクトリを /content/sam3 に変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "    \n",
    "    print(\"セットアップが完了しました。\")\n",
    "    print(f\"現在の作業ディレクトリ: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-data-usage",
   "metadata": {},
   "source": [
    "### データの使用について\n",
    "\n",
    "- **Google Driveを使用する場合**: `GT_DIR` や `PRED_DIR` には `/content/drive/MyDrive/...` から始まるパスを指定してください。\n",
    "- **GitHubからクローンした場合**: 左側のファイルブラウザから `/content/sam3` 内を確認できます。データは別途アップロードが必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-setup-explanation",
   "metadata": {},
   "source": [
    "## 環境設定 (Environment Set-up)\n",
    "\n",
    "まず、必要なライブラリをインストールし、環境をセットアップします。\n",
    "Google Colabを使用している場合は、`using_colab = True` に設定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib scikit-learn\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam3.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90073483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import sam3\n",
    "from sam3.train.data.collator import collate_fn_api as collate\n",
    "from sam3.model.utils.misc import copy_data_to_device\n",
    "import os\n",
    "sam3_root = os.path.join(os.path.dirname(sam3.__file__), \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13325376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Ampere GPU向けにtfloat32を有効化\n",
    "# https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# ノートブック全体でbfloat16を使用。カードがサポートしていない場合はfloat16を試してください\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "# ノートブック全体で推論モードを使用。勾配が必要な場合は無効にしてください\n",
    "torch.inference_mode().__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb863772",
   "metadata": {},
   "source": [
    "# ユーティリティ (Utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plotting-title",
   "metadata": {},
   "source": [
    "## プロット (Plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plotting-explanation",
   "metadata": {},
   "source": [
    "このセクションには、画像の上にマスクとバウンディングボックスをプロットするためのシンプルなユーティリティが含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(f\"{sam3_root}/examples\")\n",
    "\n",
    "from sam3.visualization_utils import plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batching-title",
   "metadata": {},
   "source": [
    "## バッチ処理 (Batching)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batching-explanation",
   "metadata": {},
   "source": [
    "このセクションには、データポイントを作成するためのいくつかのユーティリティ関数が含まれています。これらは必須ではありませんが、どのようにデータを作成すべきかについての良い指針となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batching-funcs-explanation",
   "metadata": {},
   "source": [
    "以下の関数は、推論のためのデータを構築するヘルパー関数です。\n",
    "- `create_empty_datapoint`: 空のデータポイントを作成します。\n",
    "- `set_image`: データポイントに画像を設定します。\n",
    "- `add_text_prompt`: テキストプロンプト（例：「猫」）を追加します。\n",
    "- `add_visual_prompt`: ボックスプロンプト（バウンディングボックス）を追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam3.train.data.sam3_image_dataset import InferenceMetadata, FindQueryLoaded, Image as SAMImage, Datapoint\n",
    "from typing import List\n",
    "\n",
    "GLOBAL_COUNTER = 1\n",
    "def create_empty_datapoint():\n",
    "    \"\"\" データポイントは、複数のクエリを一度に適用できる単一の画像です。 \"\"\"\n",
    "    return Datapoint(find_queries=[], images=[])\n",
    "\n",
    "def set_image(datapoint, pil_image):\n",
    "    \"\"\" 処理する画像をデータポイントに追加します \"\"\"\n",
    "    w,h = pil_image.size\n",
    "    datapoint.images = [SAMImage(data=pil_image, objects=[], size=[h,w])]\n",
    "\n",
    "def add_text_prompt(datapoint, text_query):\n",
    "    \"\"\" テキストクエリをデータポイントに追加します \"\"\"\n",
    "\n",
    "    global GLOBAL_COUNTER\n",
    "    # この関数では、画像がすでに設定されている必要があります。\n",
    "    # これは、マスクとボックスをリサイズする次元を把握するために画像のサイズを取得するためです。\n",
    "    # 実際には、任意のサイズを設定できますが、関数の残りの部分を編集してください。\n",
    "    assert len(datapoint.images) == 1, \"please set the image first\"\n",
    "\n",
    "    w, h = datapoint.images[0].size\n",
    "    datapoint.find_queries.append(\n",
    "        FindQueryLoaded(\n",
    "            query_text=text_query,\n",
    "            image_id=0,\n",
    "            object_ids_output=[], # 推論では未使用\n",
    "            is_exhaustive=True, # 推論では未使用\n",
    "            query_processing_order=0,\n",
    "            inference_metadata=InferenceMetadata(\n",
    "                coco_image_id=GLOBAL_COUNTER,\n",
    "                original_image_id=GLOBAL_COUNTER,\n",
    "                original_category_id=1,\n",
    "                original_size=[w, h],\n",
    "                object_id=0,\n",
    "                frame_index=0,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    GLOBAL_COUNTER += 1\n",
    "    return GLOBAL_COUNTER - 1\n",
    "\n",
    "def add_visual_prompt(datapoint, boxes:List[List[float]], labels:List[bool], text_prompt=\"visual\"):\n",
    "    \"\"\" ビジュアルクエリをデータポイントに追加します。\n",
    "    bboxesはXYXY形式（左上と右下のコーナー）であることが期待されます。\n",
    "    各bboxに対して、ラベル（TrueまたはFalse）が必要です。モデルは、ネガティブなものを避けながら、ポジティブなものに似たボックスを見つけようとします。\n",
    "    追加のヒントとしてtext_promptを与えることもできます。必須ではありません。モデルにボックスのみに依存させたい場合は \"visual\" のままにしてください。\n",
    "\n",
    "    モデルはプロンプトが一貫していることを期待することに注意してください。テキストが「象」と書かれているのに、提供されたボックスが犬を指している場合、結果は未定義になります。\n",
    "    \"\"\"\n",
    "\n",
    "    global GLOBAL_COUNTER\n",
    "    # この関数では、画像がすでに設定されている必要があります。\n",
    "    # これは、マスクとボックスをリサイズする次元を把握するために画像のサイズを取得するためです。\n",
    "    # 実際には、任意のサイズを設定できますが、関数の残りの部分を編集してください。\n",
    "    assert len(datapoint.images) == 1, \"please set the image first\"\n",
    "    assert len(boxes) > 0, \"please provide at least one box\"\n",
    "    assert len(boxes) == len(labels), f\"Expecting one label per box. Found {len(boxes)} boxes but {len(labels)} labels\"\n",
    "    for b in boxes:\n",
    "        assert len(b) == 4, f\"Boxes must have 4 coordinates, found {len(b)}\"\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.bool).view(-1)\n",
    "    if not labels.any().item() and text_prompt==\"visual\":\n",
    "        print(\"Warning: you provided no positive box, nor any text prompt. The prompt is ambiguous and the results will be undefined\")\n",
    "    w, h = datapoint.images[0].size\n",
    "    datapoint.find_queries.append(\n",
    "        FindQueryLoaded(\n",
    "            query_text=text_prompt,\n",
    "            image_id=0,\n",
    "            object_ids_output=[], # 推論では未使用\n",
    "            is_exhaustive=True, # 推論では未使用\n",
    "            query_processing_order=0,\n",
    "            input_bbox=torch.tensor(boxes, dtype=torch.float).view(-1,4),\n",
    "            input_bbox_label=labels,\n",
    "            inference_metadata=InferenceMetadata(\n",
    "                coco_image_id=GLOBAL_COUNTER,\n",
    "                original_image_id=GLOBAL_COUNTER,\n",
    "                original_category_id=1,\n",
    "                original_size=[w, h],\n",
    "                object_id=0,\n",
    "                frame_index=0,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    GLOBAL_COUNTER += 1\n",
    "    return GLOBAL_COUNTER - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading-title",
   "metadata": {},
   "source": [
    "# 読み込み (Loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-model-explanation",
   "metadata": {},
   "source": [
    "まず、モデルを読み込みます。`build_sam3_image_model` 関数を使用し、BPE（Byte Pair Encoding）語彙ファイルのパスを指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ec8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam3 import build_sam3_image_model\n",
    "\n",
    "bpe_path = f\"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "model = build_sam3_image_model(bpe_path=bpe_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transforms-explanation",
   "metadata": {},
   "source": [
    "次に、検証用の変換（transforms）を定義します。\n",
    "ここでは、画像を1008x1008にリサイズし、テンソルに変換してから正規化を行う一連の処理を定義しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ac22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam3.train.transforms.basic_for_api import ComposeAPI, RandomResizeAPI, ToTensorAPI, NormalizeAPI\n",
    "\n",
    "from sam3.model.position_encoding import PositionEmbeddingSine\n",
    "transform = ComposeAPI(\n",
    "    transforms=[\n",
    "        RandomResizeAPI(sizes=1008, max_size=1008, square=True, consistent_transform=False),\n",
    "        ToTensorAPI(),\n",
    "        NormalizeAPI(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postprocessor-explanation",
   "metadata": {},
   "source": [
    "そして最後に、ポストプロセッサ（後処理）を定義します。\n",
    "モデルの出力を処理し、マスクやバウンディングボックスを元の画像サイズに戻したり、信頼度閾値に基づいてフィルタリングしたりします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam3.eval.postprocessors import PostProcessImage\n",
    "postprocessor = PostProcessImage(\n",
    "    max_dets_per_img=-1,       # この数が正の場合、プロセッサはtopkを返します。このデモでは代わりに信頼度で制限します（下記参照）\n",
    "    iou_type=\"segm\",           # マスクが必要です\n",
    "    use_original_sizes_box=True,   # ボックスは画像サイズにリサイズされるべきです\n",
    "    use_original_sizes_mask=True,   # マスクは画像サイズにリサイズされるべきです\n",
    "    convert_mask_to_rle=False, # ポストプロセッサはRLE形式への効率的な変換をサポートしています。このデモでは簡単なプロットのためにバイナリ形式を好みます\n",
    "    detection_threshold=0.5,   # 信頼度の高い検出のみを返す\n",
    "    to_cpu=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-title",
   "metadata": {},
   "source": [
    "# 推論 (Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-steps",
   "metadata": {},
   "source": [
    "推論の手順は以下の通りです：\n",
    "- 上記の関数を使用して、データポイントを1つずつ作成します。作成する各クエリには一意のIDが付与され、後処理後に結果を取得するために使用されます。\n",
    "- 各データポイントは、前処理変換に従って変換する必要があります（基本的には1008x1008にリサイズし、正規化します）。\n",
    "- その後、すべてのデータポイントをバッチにまとめ、モデルに渡します（フォワードパス）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-prep-explanation",
   "metadata": {},
   "source": [
    "### データ準備\n",
    "ここでは2つの画像を準備します。\n",
    "1. **画像1**: インターネット上の画像を使用し、\"cat\"（猫）と \"laptop\"（ノートPC）という2つのテキストプロンプトを与えます。\n",
    "2. **画像2**: 別の画像を使用し、\"pot\"（鍋）というテキストプロンプトと、オーブンのダイヤルやボタンを指定するボックスプロンプトを与えます。また、ネガティブプロンプト（除外したい領域）の使用例も示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像1、2つのテキストプロンプトを使用します\n",
    "\n",
    "img1 = Image.open(BytesIO(requests.get(\"http://images.cocodataset.org/val2017/000000077595.jpg\").content))\n",
    "datapoint1 = create_empty_datapoint()\n",
    "set_image(datapoint1, img1)\n",
    "id1 = add_text_prompt(datapoint1, \"cat\")\n",
    "id2 = add_text_prompt(datapoint1, \"laptop\")\n",
    "\n",
    "datapoint1 = transform(datapoint1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a14560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像2、1つのテキストプロンプト、いくつかのビジュアルプロンプト\n",
    "img2 = Image.open(BytesIO(requests.get(\"http://images.cocodataset.org/val2017/000000136466.jpg\").content))\n",
    "\n",
    "# img2 = Image.open(f\"{sam3_root}/assets/images/test_image.jpg\")\n",
    "datapoint2 = create_empty_datapoint()\n",
    "set_image(datapoint2, img2)\n",
    "id3 = add_text_prompt(datapoint2, \"pot\")\n",
    "# オーブンのダイヤルを見つけようとしています。ポジティブなボックスを与えましょう\n",
    "id4 = add_visual_prompt(datapoint2, boxes=[[ 59, 144,  76, 163]], labels=[True])\n",
    "# オーブンの開始/停止ボタンも取得しましょう\n",
    "id5 = add_visual_prompt(datapoint2, boxes=[[ 59, 144,  76, 163],[ 87, 148, 104, 159]], labels=[True, True])\n",
    "# 次に、鍋の取っ手を見つけようとします。テキストプロンプト \"handle\"（意図的に曖昧にしています）では、モデルはオーブンの取っ手も見つけます\n",
    "# テキストクエリをより正確にすることもできますが（試してみてください！）、この例では代わりにネガティブプロンプトを活用したいと考えています\n",
    "# まず、テキストプロンプトだけで何が起こるか見てみましょう\n",
    "id6 = add_text_prompt(datapoint2, \"handle\")\n",
    "# 今度は同じですが、ネガティブプロンプトを追加します\n",
    "id7 = add_visual_prompt(datapoint2, boxes=[[ 40, 183, 318, 204]], labels=[False], text_prompt=\"handle\")\n",
    "\n",
    "datapoint2 = transform(datapoint2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-creation-explanation",
   "metadata": {},
   "source": [
    "### バッチ作成\n",
    "作成したデータポイントを `collate` 関数を使ってバッチにまとめ、GPU（CUDA）に転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチにまとめてからcudaに移動\n",
    "batch = collate([datapoint1, datapoint2], dict_key=\"dummy\")[\"dummy\"]\n",
    "batch = copy_data_to_device(batch, torch.device(\"cuda\"), non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-exec-explanation",
   "metadata": {},
   "source": [
    "### モデル実行\n",
    "バッチをモデルに入力して推論を実行し、その出力をポストプロセッサで処理して最終的な結果を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-exec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォワードパス。最初のフォワードはコンパイルのため非常に遅くなることに注意してください\n",
    "output = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results = postprocessor.process_results(output, batch.find_metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plotting-results-title",
   "metadata": {},
   "source": [
    "# プロット (Plotting)\n",
    "\n",
    "最後に、得られた結果（マスクとバウンディングボックス）を画像上にプロットして確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plotting-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(processed_results, [id1, id2, id3, id4, id5, id6, id7], [img1, img1, img2, img2, img2, img2, img2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}