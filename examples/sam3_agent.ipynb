{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM 3 エージェント (SAM 3 Agent)\n",
    "\n",
    "このノートブックでは、MLLM (Multi-modal Large Language Model) が SAM 3 をツールとして使用する例、すなわち「SAM 3 エージェント」について解説します。\n",
    "これにより、「青いベストを着ている一番左の子供 (the leftmost child wearing blue vest)」のような、より複雑なテキストクエリに基づいたセグメンテーションが可能になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-setup-md",
   "metadata": {},
   "source": [
    "## Google Colab セットアップ\n",
    "\n",
    "Google Colabで実行する場合は、以下のセルを実行してください。\n",
    "これにより、必要なライブラリのインストールと、データの読み込み準備が行われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab環境のセットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Colab環境で実行中\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ローカル環境で実行中\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Google Driveをマウント (推奨)\n",
    "    # 自分のデータやコードを使用する場合は、Google Driveにアップロードしてマウントします\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # 2. SAM3のインストールとパス設定\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    # Google Drive内のSAM3ディレクトリのパス\n",
    "    # ※ご自身の環境に合わせてパスを変更してください\n",
    "    DRIVE_SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "    \n",
    "    if os.path.exists(DRIVE_SAM3_PATH):\n",
    "        print(f\"Google Drive内のSAM3が見つかりました: {DRIVE_SAM3_PATH}\")\n",
    "        os.chdir(DRIVE_SAM3_PATH)\n",
    "        print(\"カレントディレクトリを変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        print(\"依存関係をインストールしています...\")\n",
    "        # Numpy 2.0との互換性問題を回避するためにバージョンを固定\n",
    "        !pip install -q \"numpy<2.0\"\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "        \n",
    "    else:\n",
    "        print(f\"Google Drive内に {DRIVE_SAM3_PATH} が見つかりませんでした。\")\n",
    "        print(\"GitHubからSAM3をクローンしてインストールします...\")\n",
    "        \n",
    "        # GitHubからクローン\n",
    "        if not os.path.exists(\"/content/sam3\"):\n",
    "            !git clone https://github.com/facebookresearch/sam3.git /content/sam3\n",
    "            \n",
    "        os.chdir(\"/content/sam3\")\n",
    "        print(\"カレントディレクトリを /content/sam3 に変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        # Numpy 2.0との互換性問題を回避するためにバージョンを固定\n",
    "        !pip install -q \"numpy<2.0\"\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "    \n",
    "    print(\"セットアップが完了しました。\")\n",
    "    print(f\"現在の作業ディレクトリ: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-data-usage",
   "metadata": {},
   "source": [
    "### データの使用について\n",
    "\n",
    "- **Google Driveを使用する場合**: `GT_DIR` や `PRED_DIR` には `/content/drive/MyDrive/...` から始まるパスを指定してください。\n",
    "- **GitHubからクローンした場合**: 左側のファイルブラウザから `/content/sam3` 内を確認できます。データは別途アップロードが必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab環境のセットアップ\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Colab環境で実行中\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ローカル環境で実行中\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Google Driveをマウント (推奨)\n",
    "    # 自分のデータやコードを使用する場合は、Google Driveにアップロードしてマウントします\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # 2. SAM3のインストールとパス設定\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    # Google Drive内のSAM3ディレクトリのパス\n",
    "    # ※ご自身の環境に合わせてパスを変更してください\n",
    "    DRIVE_SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "    \n",
    "    if os.path.exists(DRIVE_SAM3_PATH):\n",
    "        print(f\"Google Drive内のSAM3が見つかりました: {DRIVE_SAM3_PATH}\")\n",
    "        os.chdir(DRIVE_SAM3_PATH)\n",
    "        print(\"カレントディレクトリを変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        print(\"依存関係をインストールしています...\")\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "        \n",
    "    else:\n",
    "        print(f\"Google Drive内に {DRIVE_SAM3_PATH} が見つかりませんでした。\")\n",
    "        print(\"GitHubからSAM3をクローンしてインストールします...\")\n",
    "        \n",
    "        # GitHubからクローン\n",
    "        if not os.path.exists(\"/content/sam3\"):\n",
    "            !git clone https://github.com/facebookresearch/sam3.git /content/sam3\n",
    "            \n",
    "        os.chdir(\"/content/sam3\")\n",
    "        print(\"カレントディレクトリを /content/sam3 に変更しました。\")\n",
    "        \n",
    "        # 依存関係のインストール\n",
    "        !pip install -q -e .\n",
    "        !pip install -q pycocotools\n",
    "    \n",
    "    print(\"セットアップが完了しました。\")\n",
    "    print(f\"現在の作業ディレクトリ: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-data-usage",
   "metadata": {},
   "source": [
    "### データの使用について\n",
    "\n",
    "- **Google Driveを使用する場合**: `GT_DIR` や `PRED_DIR` には `/content/drive/MyDrive/...` から始まるパスを指定してください。\n",
    "- **GitHubからクローンした場合**: 左側のファイルブラウザから `/content/sam3` 内を確認できます。データは別途アップロードが必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境設定 (Env Setup)\n",
    "\n",
    "まず、リポジトリの [インストール手順](https://github.com/facebookresearch/sam3?tab=readme-ov-file#installation) に従って、環境に `sam3` をインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Ampere GPU向けにtfloat32を有効化\n",
    "# https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# ノートブック全体でbfloat16を使用。GPUがサポートしていない場合はfloat16を試してください\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "# ノートブック全体で推論モードを使用。勾配が必要な場合は無効にしてください\n",
    "torch.inference_mode().__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SAM3_ROOT = os.path.dirname(os.getcwd())\n",
    "os.chdir(SAM3_ROOT)\n",
    "\n",
    "# 使用するGPUを設定 - このデモの目的には単一のGPUで十分です\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "_ = os.system(\"nvidia-smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM3モデルの構築 (Build SAM3 Model)\n",
    "\n",
    "SAM3の画像モデルとプロセッサを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sam3\n",
    "from sam3 import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "sam3_root = os.path.join(os.path.dirname(sam3.__file__), \"..\")\n",
    "bpe_path = f\"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "model = build_sam3_image_model(bpe_path=bpe_path)\n",
    "processor = Sam3Processor(model, confidence_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMの設定 (LLM Setup)\n",
    "\n",
    "使用するMLLMを設定します。自分のマシンから起動するvLLMによって提供されるモデル、または外部API経由で提供されるモデルのいずれかを選択できます。\n",
    "vLLMモデルを使用したい場合は、以下の手順も参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_CONFIGS = {\n",
    "    # vLLMで提供されるモデル\n",
    "    \"qwen3_vl_8b_thinking\": {\n",
    "        \"provider\": \"vllm\",\n",
    "        \"model\": \"Qwen/Qwen3-VL-8B-Thinking\",\n",
    "    }, \n",
    "    # 外部API経由で提供されるモデル\n",
    "    # 必要に応じて追加してください\n",
    "}\n",
    "\n",
    "model = \"qwen3_vl_8b_thinking\"\n",
    "LLM_API_KEY = \"DUMMY_API_KEY\"\n",
    "\n",
    "llm_config = LLM_CONFIGS[model]\n",
    "llm_config[\"api_key\"] = LLM_API_KEY\n",
    "llm_config[\"name\"] = model\n",
    "\n",
    "# APIエンドポイントの設定\n",
    "if llm_config[\"provider\"] == \"vllm\":\n",
    "    LLM_SERVER_URL = \"http://0.0.0.0:8001/v1\"  # 必要に応じてvLLMサーバーのアドレスに置き換えてください\n",
    "else:\n",
    "    LLM_SERVER_URL = llm_config[\"base_url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vLLMサーバーのセットアップ (Setup vLLM server)\n",
    "\n",
    "この手順は、vLLMによって提供されるモデルを使用している場合にのみ必要です。GeminiやGPTなどのAPIを使用してLLMを呼び出す場合は、この手順をスキップしてください。\n",
    "\n",
    "* vLLMをインストールします (依存関係の競合を避けるため、SAM 3とは別のconda環境にインストールしてください)。\n",
    "  ```bash\n",
    "    conda create -n vllm python=3.12\n",
    "    pip install vllm --extra-index-url https://download.pytorch.org/whl/cu128\n",
    "  ```\n",
    "* このノートブックと同じマシン上でvLLMサーバーを起動します。\n",
    "  ```bash\n",
    "    # qwen 3 VL 8B thinking\n",
    "    vllm serve Qwen/Qwen3-VL-8B-Thinking --tensor-parallel-size 4 --allowed-local-media-path / --enforce-eager --port 8001\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM3エージェント推論の実行 (Run SAM3 Agent Inference)\n",
    "\n",
    "画像とプロンプトを指定して、SAM3エージェントによる推論を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from IPython.display import display, Image\n",
    "from sam3.agent.client_llm import send_generate_request as send_generate_request_orig\n",
    "from sam3.agent.client_sam3 import call_sam_service as call_sam_service_orig\n",
    "from sam3.agent.inference import run_single_image_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 689664053567678,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "# 入力引数の準備と単一画像推論の実行\n",
    "image = \"assets/images/test_image.jpg\"\n",
    "prompt = \"the leftmost child wearing blue vest\"\n",
    "image = os.path.abspath(image)\n",
    "send_generate_request = partial(send_generate_request_orig, server_url=LLM_SERVER_URL, model=llm_config[\"model\"], api_key=llm_config[\"api_key\"])\n",
    "call_sam_service = partial(call_sam_service_orig, sam3_processor=processor)\n",
    "output_image_path = run_single_image_inference(\n",
    "    image, prompt, llm_config, send_generate_request, call_sam_service, \n",
    "    debug=True, output_dir=\"agent_output\"\n",
    ")\n",
    "\n",
    "# 出力の表示\n",
    "if output_image_path is not None:\n",
    "    display(Image(filename=output_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "be59e249-6c09-4634-a9e7-1f06fd233c42",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}